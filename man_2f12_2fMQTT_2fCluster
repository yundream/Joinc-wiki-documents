#title MQTT Cluster 구성
[[TableOfContents]]
== MQTT Cluster ==
MQTT Cluster를 구성하는 목적은 아래와 같다. 
  1. 대량의 메시지 처리 : 수백/수천만의 MQTT 클라이언트 요청을 처리할 수 있어야 한다. 당장 만들겠다는 것은 아니고, 목표는 그렇게 잡아보자는 이야기다. 꿈의 크기야 뭐 제한이 없으니까. 
  1. 고가용성 : 안정적으로 서비스 할 수 있어야 한다. 서버 구성요소 중 하나 이상에 문제가 생기더라도, 서비스 제공이 가능해야 한다.   
  1. 확장성 : Cluster에 노드를 추가하는 것으로 간단하게 서비스를 확장할 수 있어야 한다. 

=== 서비스  소개 ===
어떤 타입의 서비스인지에 따라서 클러스터 구성 기술이 달라질 수 있기 때문에, 서비스를 특정하기로 했다. 가장 무난한 멀티 클라이언트 채팅 시스템을 선택했다. 원래는 IoT 기기로 부터의 센서 데이터 수집을 선택하려 했는데, 개념을 설명하는데는 일반적인 서비스가 나을 것 같아서 채팅 시스템으로 변경했다. 

서비스의 기능은 다음과 같다.
  1. Private channel을 가진다. Private channel을 이용해서 단일 유저에게 메시지를 보낼 수 있다. 
  1. Group channel을 가진다. 한 명 이상의 유저가 참여하는 Topic이다. 뉴스라면 구독 서비스가 되겠고, 채팅이라면 채팅방 서비스가 되겠다. 
  1. 개인 메시지 함 : 유저가 연결하지 않은 경우, 유저 수신 메시지를 임시 저장하기 위한 서비스 

== 설계 ==
=== 시스템 구성 ===
시스템은 대략 다음과 같이 구성한다.

{{{#!html
<img src="https://docs.google.com/drawings/d/1T-EWLsSE80THwMQpTTlXnrxUe8mgqe8pEZ5M0b94-M0/pub?w=673&amp;h=411">
}}}

Node-1, Node-2는 유저의 Private channel(MQTT Topic)을 유지한다. Private channel로 보낸 메시지는 "Global message proc(이하 GMP)"로 보낸다. Global message proc는 이 메시지를 Message Queue에 적재한다. 이때, 유저 연결 테이블을 확인해서 유저가 어느 Node에 있는지를 찾아낸다. Node ID를 찾았다면, Node ID를 Key로 REDIS 에 밀어 넣는다. 

User ID를 Key로 하지 않는 이유는 User ID를 key로 할 경우, 각 노드는 User ID의 갯수만큼 list에 접근을 해야 하는 문제가 있기 때문이다. Node ID로 하면, 한번에 자신의 데이터를 읽을 수 있다.

메시지 전송시점에  메시지 수신자가 연결하지 않았을 수도 있다. 이 경우 GMP는 유저 메시지 함에 메시지를 보내면 된다. 메시지 함은 User ID가 Key인 REDIS List로 관리한다. 새로 연결한 유저는 메시지 함에 읽지 않는 메시지가 있는지를 확인하는 과정을 거친다. GMP가 메시지함에 메시지를 쓰는 걸 끝내기 전에, 유저 가 연결을 끝내버릴 수도 있다. 이 경우, 유저는 다음 연결 전까지는 메시지함의 메시지를 확인할 수 없게 된다. 해결 방법을 고민해 보자면
  * 새로 연결한 유저는 수초 정도 후에, 메시지 함을 한번 읽도록 코드를 만든다. 
  * 메시지함을 읽는 초기 간격을 너무 길게 하면 메시지 반응성이 떨어지고, 너무 짧게하면, 메시지 함에 늦게 도착하는 경우가 생길 수 있다. 1초, 10초, 1분 이렇게 3번 정도 다른 간격으로 읽게하면 문제를 해결할 수 있다.

=== Group Table ===
라우팅 테이블의 데이터 구조는 대략 아래와 같을 것이다.
{{{#!plain
Group Table
  - Group A : {user-1, user-2, user-3}  
  - Group B : {user-1, user-4, user-5}
}}}

=== 유저 연결 상태 ===
REDIS BitMap으로 구현한다. 클라이언트의 연결 상태(0 or 1)을 저장하는 BitMap 테이블이다. 클라이언트의 연결 정보는 다른 테이블에 저장한다. 연결 상태를 따로 저장하는 이유는 아래와 같다.  
  * 클라이언트의 연결 정보는 '''Hash(REDIS 자료구조)'''로 구성해야 할 건데, Hash에서 데이터 검색은 꽤 많은 시간이 걸린다. 
  * 그룹의 유저에게 메시지를 보낸다고 가정해보자. 이 그룹에는 10명의 유저가 있는데, 현재 2명만 연결된 상태다. Hash 만 이용할 경우 10번의 Hash 연산이 필요하다. 
  * 클라이언트의 연결 정보는 BitMap으로 구성할 수 있는데, BitMap 연산은 O(1)이다. 연결하지 않은 8명의 유저의 경우 바로 메시지 함으로 메시지를 보내면 되고, 2명의 유저에 대해서만 연결정보를 찾아서 메시지를 전송하면 된다. 

=== 메시지 함 ===
유저가 받지 못한 메시지를 임시 저장하기 위한 공간이다. 유저가 연결하면 먼저 메시지함의 메시지를 처리하도록 한다. 역시 REDIS로 구성한다.

{{{#!html
<img src="https://docs.google.com/drawings/d/1km7_A5PI7xvSrIYVDpKtYMFQ5mBLnxKQBfZIE8vTdSM/pub?w=514&amp;h=350">
}}}

자료 타입으로 리스트(List)를 선택했다. User의 ID를 Key로 하고, 메시지는 '''LPUSH'''로 밀어 넣는다. 이렇게 구성하는 이유는 다음과 같다. 
  * User ID를 Key로 List를 만든다. 직관적이다.
  * 유저가 메시지를 소비하지 않을 경우 List에 계속 데이터가 쌓일 거다. 무한대로 쌓아둘 수는 없으니 크기에 제한을 둬야 하는데, LPUSH와 LTRIM 조합으로 하면, 리스트 크기를 관리하기가 쉽다. 예를들어 최근 1000개의 메시지만 남기고, 오래된 메시지는 삭제(혹은 다른 데이터베이스에 저장)하는 식의 구현이 가능하다. 

=== 메시지 흐름 ===
메시지 흐름을 자세히 그려보았다.

{{{#!html
<img src="https://docs.google.com/drawings/d/1S5xPtuMvE6h8Sg0U4XkCm5ki1PfD3OnXYqWGtvwPwJY/pub?w=933&amp;h=518">
}}}
  * MQTT Client는 '''Private topic'''만 가진다. 이 Private topic으로 모든 메시지를 받도록 구성한다. 예컨데, 그룹 메시지도 private topic "그룹타입의 메시지 형태"로 보낸다. 
  * 메시지는 Msg Sender로 보낸다.  
  * Msg Sender은 Global Message Proc로 보낸다.  
  * Global Message Proc는 private message인지, Group message인지를 확인해서 처리한다.
    * private message라면, user_id를 key로 하는 REDIS list에 밀어 넣는다.
    * group message라면, 유저 목록을 찾아서 user_id 갯수 만큼 REDIS list에 밀어 넣는다.
  * 각 Node에 있는 Message proc는 메시지를 읽어서 수신 유저의 topic에 PUB 한다. 
REDIS Message Queue는 '''BLPOP'''를 이용하면 블럭킹 모드에서 데이터를 꺼낼 수 있다. 여기에서는 Message queue를 이용해서 메시지를 분배하고 있는데, HTTP로 분배하는 방법을 고려할 수도 있다. 장/단점이 있는데
  1. Message Queue는 HTTP 보다 효율적으로 작동한다. 반면에 MQTT Node가 뻗어버릴 경우 Message Queue에 있는 메시지를 처리하기가 까다롭다는 단점이 있다.
  1. HTTP는 Message Queue보다 느리게 작동할 거다. 하지만 동기방식이기 때문에, 에러처리가 명확하다는 장점이 있다. 메시지를 수신할 MQTT 노드가 뻗었다면, 메시지 함에 넣기만 하면 된다. 

장/단점을 적어 놓고 보니, Message Queue 보다는 HTTP로 Message proc에 직접 쏴주는 방식이 낫겠다는 생각이 든다.
== MQTT 클러스터 관리 ==
=== 모니터링 소프트웨어를 이용한 간단한 구성 ===
나는 간단한 시스템을 만들기를 원한다. 클러스터의 노드를 관리하기 위해서 어떤 새로운 자료구조를 유지하는 소프트웨어를 설치하는 등의 복잡함을 피하고 싶다.

{{{#!html
<img src="https://docs.google.com/drawings/d/1TZHnhosVjybhWMjVKKw1CDY9q48EZn3s6TuoujBwGAY/pub?w=1044&amp;h=717">
}}}

=== Redis를 이용한 유저 연결정보 관리 ===
이 시스템의 가장 중요한 기능은 메시지를 유저에게 까지 성공적으로 라우팅 하는 거다. 메시지 라우팅은 '''Global Message Proc'''가 담당하는데, 성공적인 라우팅을 위해서는 아래 두 정보가 필요하다. 
  1. 메시지를 수신할 클라이언트가 연결 상태에 있는가. 
  1. 메시지를 수신할 클라이언트가 어느 노드에 연결해 있는가.
이들 정보는 Redis를 이용하기로 했다. 먼저 연결 상태(on, off)는 '''User connection Bitmap'''테이블에 저장하기로 했다. BitMap은 on, off 혹은 0과 1의 상태를 저장하기에 적당한 자료구조다. 10M 정도의 공간으로 1억명의 클라이언트 연결 상태를 저장할 수 있다. 게다가 상태를 알아내기 위한 시간복잡도는 O(1)이다. BitMap의 크기는 514MB이므로, 최대 43억의 클라이언트 연결 정보를 저장할 수 있다. 

클라이언트가 연결 상태라면, '''User connection Hash''' 테이블에서 찾는다. 쉽게 생각할 수 있는 자료구조는 Hash 인데, 클라이언트의 수가 많아지면 아무래도 효율이 떨어질 수 있다. Hash를 여러개 만드는 것으로 이 문제는 해결할 수 있을 것이다.  

혹은 REDIS string 자료구조에 저장하는 방법도 있다. 노드가 최대 8192정도까지 늘어난다고 가정하면, 4자리의 (fixed-size)고정크기로 저장을 할 수 있다. 예를들어 ID가 1780인 유저라면 1780 * 4 만큼 offset해서 4byte 값을 읽는 것으로, 유저의 노드를 찾을 수 있다. 1억명의 클라이언트라고 가정하면 총 4억 byte(381M)정도의 공간이 필요하다.

{{{#!html
<img src="https://docs.google.com/drawings/d/1KVjBTCg--R-5gh4ZVjQLbM89_xT0NdgZm_Tieixxbkc/pub?w=453&amp;h=150">
}}}

Hash 보다는 fixed-side string 자료구조가 더 나은 것 같다.

=== MQTT Node의 추가 ===
Autoscaling에 맡기는 방법을 생각해 볼 수 있겠다. Cloudwatch를 이용하면 Elastic load balancer의 Latency,RequestCount 메트릭을 모니터링할 수 있다. 이들 정보를 이용해서 Scale-out 하면 된다. 

노드가 추가되면, 
=== MQTT Node의 삭제 ===
Node가 삭제되면 어떤일이 생기는지 정리해 보자. Node의 상태 정보를 가지고 있지 않다고 가정한다.
  1. 노드는 더 이상 작동하지 않지만, REDIS 정보는 그대로라서 여전히 클라이언트는 노드에 연결된 걸로 보인다.
  1. 누군가 삭제된 노드에 연결되 있는 클라이언트로 메시지를 보낸다.  
    1. 클라이언트가 다른 노드로 연결했다면, 문제될게 없다. 이 메시지는 클라이언트에게 제대로 전달 된다. 
    1. 클라이언트가 다른 노드로 연결하지 않았다면, 메시지는 전송 실패한다. 이 메시지는 메시지 함에 쌓인다.
    1. 클라이언트가 새로 연결하면, 메시지함에 있는 메시지를 읽는다. 이후 메시지는 성공적으로 전달된다.
일단 메시지는 잘 전달된다. 하지만, 존재하지 않는 노드에 계속 메시지 전송을 요청하는게 지저분하다. 역시 노드의 상태정보를 어딘가에 저장해야 할 것 같다. 

노드의 상태를 모니터링 하는 Healthcheck 프로그램의 개발이 필요하다. 어떤 정보를 모니터링을 해야 하는지가 관건이다. 
  * MQTT PING : MQTT 서비스 데몬이 살아있는지 확인한다.  
  * 요청 처리 건수 : MQTT 서비스 데몬은 살아있지만 어떤 이유로 요청이 들어오지 않을 수도 있다. 혹은 요청을 제대로 처리하지 못할 수도 있다. 이때는 서비스를 중단하고, 문제점을 찾는 활동을 하는게 낫다.
노드의 상태정보는 Redis에 저장하면 되겠다. 

Healthcheck는 Zabbix 같은 범용 모니터링 툴로도 충분할 것 같다. 주기적으로 (5초 미만으로) 모니터링 하다가 문제가 발생하면, 
  1. User connection Bitmap 에서 Node에 붙어있던 유저의 연결상태를 모두 0으로 만들어서, 유저에게 메시지가 전달되지 않도록 한다.
  1. ELB 그룹에서 문제의 노드를 제거해서, 더 이상 클라이언트 요청이 들어오지 않도록 한다.
  1. 클라이언트는 재 연결 요청을 하고, ELB는 다른 노드로 클라이언트 연결 요청을 보낸다. 
식으로 처리한다.

=== Zookeeper를 이용한 관리 ===
[wiki:man/12/zookeeper Zookeeper]에 MQTT Node를 등록해서 관리한다. 대략 구성은 다음과 같을 거다. 

{{{#!html
<img src="https://docs.google.com/drawings/d/1088XMEB7YTrE2E6HW5y4ca-qg4KkMYaeF0tq1M3sR6g/pub?w=453&amp;h=271">
}}}

Zookeeper로 MQTT Node 정보를 관리한다. Global Message Proc는 메시지를 전송하기 전에 Node가 살아있는지를 확인한다. Zookeeper은 3대 이상으로 클러스터를 구성할 수 있을 테니, 가용성 문제도 함께 해결할 수 있다. 다른 삽질 하는 것 보다 Zookeeper로 관리하는게 나은 것 같다. 
