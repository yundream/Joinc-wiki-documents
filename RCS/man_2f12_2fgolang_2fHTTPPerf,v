head	1.26;
access;
symbols;
locks
	root:1.26; strict;
comment	@# @;


1.26
date	2015.02.20.15.25.21;	author root;	state Exp;
branches;
next	1.25;

1.25
date	2015.02.20.10.42.27;	author root;	state Exp;
branches;
next	1.24;

1.24
date	2015.02.19.15.31.54;	author root;	state Exp;
branches;
next	1.23;

1.23
date	2015.02.15.06.37.55;	author root;	state Exp;
branches;
next	1.22;

1.22
date	2015.02.15.06.36.38;	author root;	state Exp;
branches;
next	1.21;

1.21
date	2015.02.15.00.08.18;	author root;	state Exp;
branches;
next	1.20;

1.20
date	2015.02.14.12.03.59;	author root;	state Exp;
branches;
next	1.19;

1.19
date	2015.02.14.11.55.58;	author root;	state Exp;
branches;
next	1.18;

1.18
date	2015.02.14.02.54.42;	author root;	state Exp;
branches;
next	1.17;

1.17
date	2015.02.14.02.25.26;	author root;	state Exp;
branches;
next	1.16;

1.16
date	2015.02.13.21.47.08;	author root;	state Exp;
branches;
next	1.15;

1.15
date	2015.02.13.21.41.27;	author root;	state Exp;
branches;
next	1.14;

1.14
date	2015.02.13.20.07.20;	author root;	state Exp;
branches;
next	1.13;

1.13
date	2015.02.13.19.55.14;	author root;	state Exp;
branches;
next	1.12;

1.12
date	2015.02.11.01.38.17;	author root;	state Exp;
branches;
next	1.11;

1.11
date	2015.02.10.16.16.03;	author root;	state Exp;
branches;
next	1.10;

1.10
date	2015.02.10.16.12.06;	author root;	state Exp;
branches;
next	1.9;

1.9
date	2015.02.10.16.07.04;	author root;	state Exp;
branches;
next	1.8;

1.8
date	2015.02.10.15.28.47;	author root;	state Exp;
branches;
next	1.7;

1.7
date	2015.02.10.15.28.34;	author root;	state Exp;
branches;
next	1.6;

1.6
date	2015.02.10.15.27.52;	author root;	state Exp;
branches;
next	1.5;

1.5
date	2015.02.10.15.25.41;	author root;	state Exp;
branches;
next	1.4;

1.4
date	2015.02.10.15.23.53;	author root;	state Exp;
branches;
next	1.3;

1.3
date	2015.02.10.15.18.08;	author root;	state Exp;
branches;
next	1.2;

1.2
date	2015.02.10.15.12.06;	author root;	state Exp;
branches;
next	1.1;

1.1
date	2015.02.10.15.08.05;	author root;	state Exp;
branches;
next	;


desc
@./data/text/man_2f12_2fgolang_2fHTTPPerf
@


1.26
log
@119.64.102.68;;yundream;;
@
text
@#title Go HTTP 패키지 성능 측정
[[TableOfContents]]
== 소개 ==
메시지 드리븐 방식의 웹 기반 API 서버를 개발해야 하는 요구 사항이 생겼다. 백엔드는 [wiki:man/12/MQTT MQTT], [wiki:man/12/REDIS REDIS] 등의 고성능 소프트웨어(혹은 프로토콜을 사용하는)로 구성할 계획이라서, '''웹 API 서버'''가 버틀랙이 될 것으로 예상하고 있다. 요즘에는 AWS로 인프라를 구축하고 있는데, '''성능은 scale-out으로 해결'''한다는 기본 방향을 가지고 있다. 하지만 요구사항이 요구사항인지라 이번에는 다른 플랫폼과 프레임워크의 도입을 검토해 보기로 했다. 

[https://www.techempower.com/benchmarks/#section=data-r9&hw=ec2&test=db Web Framework Benchmarks]의 데이터를 기준으로 C++, Java, Go 정도가 가능한 선택지였다. 이 중 Go를 선택해서 테스트 해보기로 했다.

== 비교 대상 ==
원래 Go/HTTP 패키지와 NginX만 비교해서 테스트하려 했으나, NginX, Ruby Sinatra, Node.js, Ruby Rack와 비교 테스트 하게 됐다. 이들 애플리케이션들은 일대일로 비교하기에는 성격에 차이가 있다. 예컨데, NginX는 웹서버, Go와 노드는 플랫폼, Sinatra는 마이크로 프레임워크, Revel은 풀 프레임워크, Rack은 웹 서버 인터페이스다. 애초에 직접 비교하기에는 무리가 있을 수 있는 것들을 비교했으니, 판단은 각자 기준에 따라서 알아서 해야 할 것이다.

== 비교 요소 ==
동접을 늘려가면서, 초당 요청수(Requests/sec)와 응답시간(Latency)를 측정한다.

== 테스트 ==
=== 테스트 환경  ===
EC2 인스턴스위에서 테스트한다. 
  * 테스트 인스턴스 사양 : EC2 C4.large 
  * 운영체제 : 우분투 리눅스 14.04
  * Go 언어 버전 : 1.4.1 
  * 웹 서버 : NginX
  * 트래픽 발생기 : wrk
=== 테스트 환경 구성 ===
{{{#!html
<img src="https://docs.google.com/drawings/d/1LfhAD96K57dp6xp7JWuh4gAcSau4HFBlHwPhGUv_pv0/pub?w=551&amp;h=225">
}}}

트래픽 발생서버에서 [wiki:Site/Network_Programing/AdvancedComm/HTTP HTTP] 트래픽을 만들어서 HTTP Server를 테스트 한다. HTTP Server에는 Go, NginX, 노드 등이 올라간다. 

=== wrk 설치 및 사용 ===
wrk는 ab와 같은 벤치마크 툴이다. 루아 스크립트를 이용해서 다양한 테스트가 가능하다는 장점이 있다.  
{{{#!plain
# git clone https://github.com/wg/wrk.git
# cd wrk
# make
# cp wrk /usr/local/bin
}}}

테스트 방법
{{{#!plain
# wrk -t 16 -c 64 -d10s http://10.100.1.62:8080/
Running 10s test @@ http://10.100.1.62:8080/
  16 threads and 64 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     8.41ms   73.74ms   1.63s    98.79%
    Req/Sec     3.29k     1.33k   12.11k    68.95%
  499469 requests in 9.99s, 60.97MB read
Requests/sec:  49991.66
Transfer/sec:      6.10MB
}}}
t는 스레드의 갯수, c는 동시접속 갯수, d는 테스트 시간이다. 위 예제의 경우 16개의 스레드를 이용해서 64개의 동접 상황을 만들어서 10초 동안 테스트한다. 위 결과에서 '''Latency'''와 '''Requests/sec''' 정보를 수집한다.

'''동접'''이라는 것에 대해서 정의하고 넘어가야 겠다. 여기에서 동접은 netstat를 찍었을 때 '''ESTABLISHED'''상태인 연결의 갯수를 의미한다. -c 64라는 것은 64개의 ESTABLISHED 연결을 유지한다는 의미가 되겠다. wrk는 16개의 스레드를 유지하면서 64개의 연결을 유지한다. 만약 하나의 연결이 종료가 되면, 즉시 새로운 연결을 만들어서 64개를 계속 유지하는 방식으로 작동한다. 

=== 테스트 스크립트 ===
wrk 테스트 결과는 GNUPlot 으로 시각화 한다. 이를 위해서 wrk의 출력결과를 GNUPlot 형식으로 만들어주는 간단한 스크립트를 만들었다. 
{{{#!plain
import os
import re
import time

def report(c, lines):
    rtv = []
    for str in lines:
        str=re.sub("^[ \t]+",'', str)
        if str.find("Latency") == 0 or str.find("Requests/sec") == 0:
            token = re.split("[ \t]+", str)
            value = re.sub("[^0-9\.]", '', token[1])
            if re.match("[0-9\.]+us", token[1]):
                rtv.append(float(value)/1000)
            elif re.match("[0-9\.]+s", token[1]):
                rtv.append(float(value)*1000)
            else:
                rtv.append(float(value))
    print c,"\t", rtv[0],"\t",rtv[1]

def run(cmd):
    stdin, stdout, stderr = os.popen3(cmd)
    return stdout.readlines()

offset = 5
maxConcurrency = offset * 61
duration = 10
for num in range(1, maxConcurrency/offset):
    concurrency = num * offset
    thread = 16 if concurrency > 16 else concurrency
    cmd = ("wrk -t %d -c %d -d %ds http://10.100.1.62:8080" % (thread, concurrency, duration))
    result =run(cmd)
    report(concurrency, result)
    time.sleep(5)
}}}
실행 결과
{{{#!plain
5       0.16345         30205.66
10      0.21071         48597.58
15      0.38523         50011.98
20      0.4249          50039.27
25      0.41185         50069.66
30      0.45189         50044.11
35      0.72995         50081.43
40      0.71449         50073.36
45      0.73107         50097.2
50      10.41           50024.7
55      16.69           50039.07
60      12.05           50061.65
65      61.78           49949.86
70      80.24           50003.17
75      73.18           49970.52
80      109.59          49912.44
}}}

=== Go 웹 서버 ===
{{{#!plain
package main

import (
	"fmt"
	"net/http"
	"runtime"
)

func main() {
	runtime.GOMAXPROCS(4)
	fmt.Println("GOMAXPROCS=", runtime.GOMAXPROCS(-1))
	fmt.Println("NumCPU=", runtime.NumCPU())
	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		fmt.Fprint(w, "Hello World")
	})
	http.ListenAndServe(":8080", nil)
}
}}}
Hello World를 출력하는 간단한 프로그램이다. GOMAXPROCS를 이용해서 4개의 CPU를 시뮬레이션 했다. GOMAXPROCS를 4로 했을 때 성능이 가장 좋았다. C4.large의 NumCPU는 2개다(/proc/cpuinfo에 나오는 CPU 갯수). 

=== NginX 설정 ===
{{{#!plain
worker_processes  4    # 보통 4로 잡는다.
worker_connection 768  # uname -a 보다 작게 잡으면 되겠다. 
}}}
한 마디로 기본 설정 그대로다.

=== Node.js ===
{{{#!plain
var http = require('http');

http.createServer(function (request, response) {
	response.writeHead(200, {'Content-Type': 'text/plain'});
    response.end('Hello World\n');
}).listen(8080);

console.log('Server started');
}}}
기본적으로 노드는 하나의 스레드로 작동한다. C4.lage 인스턴스는 2개의 CPU를 제공하므로, 이렇게 해서는 CPU 자원을 모두 사용할 수 없다. 아래의 코드로도 테스트 했다.   
{{{#!plain
ivar cluster = require('cluster');
var http = require('http');
var numCPUs = require('os').cpus().length;
console.log(numCPUs)
if (cluster.isMaster) {
  // Fork workers.
  for (var i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', function(worker, code, signal) {
    console.log('worker ' + worker.process.pid + ' died');
  });
} else {
  // Workers can share any TCP connection
  // In this case its a HTTP server
  http.createServer(function(req, res) {
    res.writeHead(200);
    res.end("hello world\n");
  }).listen(8080);
}
}}}
=== Ruby Thin Sinatra ===
Thin + Sinatra 기반으로 테스트를 진행했다. 
{{{#!plain
require 'sinatra'
set :logging, false

get '/' do
    'Hello World!'
	end
}}}

=== Revel ===
Revel은 Go로 만든 풀 프레임워크 애플리케이션이다. 아래와 같은 컨트롤러 코드를 만들었다. 테스트의 공정함을 위해서 굳이 파일에서 읽지 않고, 직접 출력하도록 복잡한 코드를 만들었다.
{{{#!plain
package controllers
import "github.com/revel/revel"
import "net/http"

type App struct {
    *revel.Controller
}

type Html string

func (r Html) Apply(req *revel.Request, resp *revel.Response) {
    resp.WriteHeader(http.StatusOK, "text/html")
    resp.Out.Write([]byte(r))
}

func (c *App) Index() revel.Result {
    return Html("Hello World")
}
}}}

=== 테스트 결과 ===
{{{#!html
<div class="row">
    <div class="large-6 columns">
        <img src="https://lh5.googleusercontent.com/-lid7C0i6Ls4/VOYBo8XPScI/AAAAAAAAEyY/wSMm5VAjusE/s800/latency.png">
    </div>
    <div class="large-6 columns">
       <img src="https://lh3.googleusercontent.com/-1CSSS3T7ipI/VOYBoplCyCI/AAAAAAAAEyY/sJMxAbbq6nQ/s800/request.png">
    </div>
</div>
}}}
  * Nginx와 Go 모두 대략 초당 50000정도의 요청을 처리할 수 잇다. 
  * 동시접속이 늘어날 수도록 응답시간이 길어진다. 유저가 참을 수 있는 응답지연을 400ms라고 할 때, NgiX와 GO 모두 동접 150 정도에서 무난하게 돌아간다.  
  * Node.js는 약간 다르다. 동접과 상관없이 일정한 지연과 초당 처리 건수를 보여준다. 스레드를 두 개로 했을 때는 (당연히) 더 많은 요청을 처리한다. 4개의 쓰레드에 대해서도 테스트 했는데, 큰 차이가 없어서 테스트 결과에 포함하지는 않았다.
  * Sinatra는 느리다. RoR도 큰 차이는 없을 것으로 보인다.
  * Revel은 풀 프레임워크라서 그런지, 꽤 느리다. 

== 정리 ==
Go/HTTP의 성능은 매우 좋긴 하지만, HTTP 패키지 만으로 생산성을 확보할 수 있을지는 걱정이 되는 부분이다. 다행?인 점은 (아마도 구글에서 만든 언어라서 그런거겠지만) HTTP 패키지가 매우 강력하다는 점이다. HTTP 패키지만으로도 웹 애플리케이션을 개발하는 데, 부족함이 없다. 

물론 그렇다고 해서 풀 프레임워크 만큼의 생산성을 보장해주는 건 아니다. MVC 모델이 필요한 복잡한 웹 애플리케이션이라면 풀 프레임워크로 개발을 하는게 맞을 것이다. 반면 REST API 서버 등에서는 특히 성능 측면에서 충분한 장점을 가지고 있다. Goji, martini와 같은 마이크로 프레임워크를 선택하는 것도 방법이다. 

== 테스트 결과 데이터 ==
 * [https://drive.google.com/open?id=0B6p_m8EvqxeuYW9DS01wNW9YTVk&authuser=0 Go HTTP 테스트 결과]
 * [https://drive.google.com/open?id=0B6p_m8EvqxeuUTNlNWI4NVFITG8&authuser=0 NginX 테스트 결과] 
 * [https://drive.google.com/open?id=0B6p_m8EvqxeuRmtMcnlxVVNjd0E&authuser=0 Node.js one thread 테스트 결과]
 * [https://drive.google.com/open?id=0B6p_m8EvqxeuUHg3S21IQUNlX28&authuser=0 Node.js two thread 테스트 결과]
@


1.25
log
@119.64.102.68;;yundream;;
@
text
@d187 1
a187 1
Revel은 Go로 만든 Full framework다. 아래와 같은 컨트롤러 코드를 만들었다. 테스트의 공정함을 위해서 굳이 파일에서 읽지 않고, 직접 출력하도록 복잡한 코드를 만들었다.
a224 1
웹 서버, 풀 프레임워크, 플랫폼이 뒤 섞인 결과임을 감안해서 판단하자. 예컨데, node.js는 플랫폼이고 revel은 풀 프레임워크이므로 이 둘을 단순히 비교하는 것은 무리가 있을 수 있다. 굳이 비교 하려면 node.js 기반의 프레임워크인 '''express''' 같은 프레임워크와 비교해야 할 것이다.(사실 express는 마이크로 프레임워크이니 이것도 공정한 비교는 아니다.) 
d226 6
a231 1
=== 테스트 결과 데이터 ===
d233 1
a233 1
 * [https://drive.google.com/open?id=0B6p_m8EvqxeuUTNlNWI4NVFITG8&authuser=0] NginX 테스트 결과] 
@


1.24
log
@119.64.102.68;;yundream;;
@
text
@d4 1
a4 1
메시지 드리븐 방식의 웹 기반 API 서버를 개발해야 하는 요구 사항이 생겼다. 백엔드는 [wiki:man/12/MQTT MQTT], [wiki:man/12/REDIS REDIS] 등의 고성능 소프트웨어(혹은 프로토콜을 사용하는)로 구성할 계획이라서, '''웹 API 서버'''가 버틀랙이 될 것으로 예상 했다. 요즘에는 AWS로 인프라를 구축하고 있고, '''성능은 scale-out'''하는 걸로 해결한다는 기본 방향을 가지고 있다. 하지만 요구사항이 요구사항인지라 이번에는 다른 플랫폼과 프레임워크의 도입을 검토해 보기로 했다. 
d9 1
a9 5
Go언어는 플랫폼이지 프레임워크는 아니다. Revel을 비롯한 몇 개의 프레임워크가 있지만, 이번에는 Go의 [wiki:Site/Network_Programing/AdvancedComm/HTTP HTTP] 패키지를 이용해서 직접 구축할 것이다. 그리고 유저 요청을 처리하는 코드도 내장 할 거다. 예컨데 웹 애플리케이션 서버인 셈이다. 

일차 비교대상은 NginX가 될 것이다. NginX는 웹 서버이므로 웹 애플리케이션 서버로 사용할 Go와 직접 비교하는 것은 무리가 있겠으나 기본적인 성능측정을 위한 용도로 사용하려 한다. 어차피 둘다 "Hello world"를 출력하는 정도라서 직접 비교해도 큰 상관이 없겠다.

이후 노드(node.js)와 비교하고 시간이 되면 flask, sinatra와 같은 경량 프레임워크와 비교한다.
d14 1
a14 1
== Go HTTP 패키지 vs NginX ==
d27 1
a27 1
트래픽 발생서버에서 HTTP 트래픽을 만들어서 HTTP Server를 테스트 한다. HTTP Server에는 Go, NginX, Node 등이 올라간다. 
@


1.23
log
@119.64.102.68;;yundream;;
@
text
@d190 23
d217 1
a217 1
        <img src="https://lh3.googleusercontent.com/-QFeWGY1Xrjc/VOA-0Cm2ZpI/AAAAAAAAEx0/gNObmYdP4pQ/s800/latency.png">
d220 1
a220 1
       <img src="https://lh6.googleusercontent.com/-1prviSxkT7w/VOA-0C1FEZI/AAAAAAAAEx4/LqxqORuOMtw/s800/request.png">
d228 2
@


1.22
log
@119.64.102.68;;yundream;;
@
text
@d204 1
a204 1
 * Sinatra는 느리다. RoR도 큰 차이는 없을 것으로 보인다.
@


1.21
log
@119.64.102.68;;yundream;;
@
text
@d179 11
d194 1
a194 1
        <img src="https://lh6.googleusercontent.com/-IzUB8yazxUc/VN83yY0tnCI/AAAAAAAAExc/E93kKpo5GeM/s800/latency.png">
d197 1
a197 1
       <img src="https://lh5.googleusercontent.com/-3OqZsLZAXQ0/VN83yVukcjI/AAAAAAAAExg/OIUoQg6LAsM/s800/request.png">
d204 1
@


1.20
log
@119.64.102.68;;yundream;;
@
text
@d4 1
a4 1
메시지 드리븐 방식의 웹 기반 API 서버를 개발해야 하는 요구 사항이 생겼다. 백엔드는 MQTT, REDIS 등의 고성능 소프트웨어(혹은 프로토콜을 사용하는)로 구성할 계획이라서, '''웹 API 서버'''가 버틀랙이 될 것으로 예상 했다. 요즘에는 AWS로 인프라를 구축하고 있고, '''성능은 scale-out'''하는 걸로 해결한다는 기본 방향을 가지고 있다. 하지만 요구사항이 요구사항인지라 이번에는 다른 플랫폼과 프레임워크의 도입을 검토해 보기로 했다. 
d9 1
a9 1
Go언어는 플랫폼이지 프레임워크는 아니다. Revel을 비롯한 몇 개의 프레임워크가 있지만, 이번에는 Go의 HTTP 패키지를 이용해서 직접 구축할 것이다. 그리고 유저 요청을 처리하는 코드도 내장 할 거다. 예컨데 웹 애플리케이션 서버인 셈이다. 
d192 2
a193 1
  * Node.js는 약간 다르다. 동접과 상관없이 일정한 지연과 초당 처리 건수를 보여준다. 스레드를 두 개로 했을 때는 (당연히) 더 많은 요청을 처리한다.
@


1.19
log
@119.64.102.68;;yundream;;
@
text
@d155 24
d192 1
a192 1
  * Node.js는 약간 다르다. 동접과 상관없이 일정한 지연과 초당 처리 건수를 보여준다. 코어를 하나만 사용하기 때문으로 보인다.
@


1.18
log
@119.64.102.68;;yundream;;
@
text
@d159 1
a159 1
        <img src="https://lh4.googleusercontent.com/-7SzF-FKTXF0/VN6zUMoBWZI/AAAAAAAAExE/DDZuYMT_9y4/s800/latency.png">
d162 1
a162 1
       <img src="https://lh4.googleusercontent.com/-cvwfAzHwSAc/VN6zUToYnNI/AAAAAAAAExI/CIco2cvuIak/s800/request.png">
d169 5
a173 4
=== 테스트에 사용한 데이터 ===
 * [https://drive.google.com/open?id=0B6p_m8EvqxeuMnFpa2VzOWo2cUE&authuser=0 Go HTTP 테스트 결과]
 * [https://drive.google.com/open?id=0B6p_m8EvqxeueEhzYnp6M2dvM2c&authuser=0 NginX 테스트 결과] 
 * [https://drive.google.com/open?id=0B6p_m8EvqxeueG9TdHlKYTgzOVU&authuser=0 Node.js 테스트 결과]
@


1.17
log
@119.64.102.68;;yundream;;
@
text
@d144 11
d162 1
a162 1
       <img src="https://https://lh4.googleusercontent.com/-cvwfAzHwSAc/VN6zUToYnNI/AAAAAAAAExI/CIco2cvuIak/s800/request.png">
d168 5
@


1.16
log
@119.64.102.68;;yundream;;
@
text
@d148 1
a148 1
        <img src="https://lh6.googleusercontent.com/-sQiH9gI-uic/VN5v0HYfLbI/AAAAAAAAEww/yGPjD21b5Cc/s800/latency.png">
d151 1
a151 1
       <img src="https://lh5.googleusercontent.com/-IYwD5ceQP0g/VN5v0SUxLrI/AAAAAAAAEww/QLDff8iChKo/s800/request.png">
@


1.15
log
@119.64.102.68;;yundream;;
@
text
@d155 2
@


1.14
log
@119.64.102.68;;yundream;;
@
text
@d138 5
d144 11
@


1.13
log
@119.64.102.68;;yundream;;
@
text
@d84 2
a85 2
offset = 4
maxConcurrency = offset * 51
d95 19
d136 3
@


1.12
log
@1.214.223.250;;yundream;;
@
text
@d4 1
a4 1
고성능 웹 서버를 만드는 프로젝트 착수. 일종의 API 서버로 유저의 요청을 최대한 빠르게 백엔드 시스템으로 보내는 일을 한다. 백엔드 시스템은 REDIS, MQTT등 경량/고속의 툴(혹은 프로토콜)들로 구성이 되기 때문에, 웹 서비스쪽이 버틀랙(Bottleneck)가 될 확률이 높다. 따라서 가능한 웹 서버의 성능을 최적화 해야 했다.
d6 23
a28 22
다양한 언어로 테스트 해야 겠는데, 우선 GO 언어로 테스트를 진행하고, Python, Ruby, Java, C(NginX) 기반 녀석들과 비교를 해보고 싶다. "Hello World"찍는 거다. 뭔가 거창한 결과를 얻기는 힘들테다.
== 환경 ==
  * 우분투 리눅스 14.10 
  * VirtualBox : 웹 서버는 게스트 운영체제에서 돌린다. 
  * 벤치마크 프로그램 : wrk
  * 시스템 정보
     * Intel(R) Core(TM) i5-4670 CPU @@ 3.40GHz
     * 8G Memory 
  * 디스크 : SSD 
    {{{#!plain
# sudo lshw -class disk
	*-disk                  
	description: ATA Disk
	product: Samsung SSD 840
	physical id: 0.0.0
	bus info: scsi@@3:0.0.0
	logical name: /dev/sda
	version: BB6Q
	serial: S1D6NSAF212973T
	size: 111GiB (120GB)
	capabilities: partitioned partitioned:dos
	configuration: ansiversion=5 sectorsize=512 signature=f81bfd4b
a29 3
== 테스트 ==
=== wrk 설치 ===
그동안 ab를 사용했다. 이번 테스트를 하면서, 웹 서비스 성능 테스트 문서들을 좀 읽었는데 '''wrk'''가 눈에 띄었다. 그래서 wrk를 선택했다. 
d31 4
a34 1
현대적인 HTTP 벤치마킹 툴이라고 한다. 
d37 1
d42 53
a94 11
=== 측정 요소들 ===
아래의 요소들을 측정한다.
  * Throughput 
  * latency 
동접을 늘려가면서 Throughput과 latency를 측정한다.

테스트 환경에도 변화를 주려고 한다.
  * CPU Core를 바꿔가면서 테스트를 진행 한다.
  * 데이터 크기
=== 로컬테스트 ===
일단 로컬(호스트 운영체제)에서 테스트를 했다. 메모리에 있는 내용을 출력하는 코드다. 
d96 1
a96 1
코어의 숫자를 바꿔 가면서 테스트했다. GOMAXPROCS는 환경변수로 설정할 수도 있다.
d107 1
a107 1
	runtime.GOMAXPROCS(2)
d109 1
d113 1
a113 145
	http.ListenAndServe(":8000", nil)
}
}}}

코어 1개로 테스트 
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://localhost:8000
Running 10s test @@ http://localhost:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.19ms  675.15us   3.32ms   59.97%
    Req/Sec     7.11k   518.90     8.89k    68.68%
  808249 requests in 10.00s, 98.66MB read
Requests/sec:  80835.59
Transfer/sec:      9.87MB
}}}

코어 2개로 테스트
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://localhost:8000
Running 10s test @@ http://localhost:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   618.83us  375.51us  18.71ms   75.70%
    Req/Sec    13.70k     0.98k   20.11k    74.10%
  1558005 requests in 10.00s, 190.19MB read
Requests/sec: 155817.06
Transfer/sec:     19.02MB
}}}

코어 4개로 테스트
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://localhost:8000
Running 10s test @@ http://localhost:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.33ms    9.34ms  63.19ms   95.66%
    Req/Sec    17.26k    13.23k  127.56k    78.16%
  1952932 requests in 10.00s, 238.40MB read
Requests/sec: 195280.00
Transfer/sec:     23.84MB
}}}

코어 8개로 테스트
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://localhost:8000
Running 10s test @@ http://localhost:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.24ms    6.02ms  81.56ms   97.27%
    Req/Sec    17.18k    10.56k  129.11k    77.61%
  1929293 requests in 9.99s, 235.51MB read
Requests/sec: 193031.78
Transfer/sec:     23.56MB
}}}

=== 원격 (게스트 운영체제) 테스트 ===
VirtualBox 게스트 운영체제로 테스트 했다.

1코어
{{{#!plain
# wrk -t 12 -c 100 -d10s http://192.168.56.100:8000
Running 10s test @@ http://192.168.56.100:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.19s   426.74ms   1.40s    88.72%
    Req/Sec     1.23k     3.08k   14.89k    92.20%
  136035 requests in 10.00s, 16.61MB read
Requests/sec:  13602.58
Transfer/sec:      1.66MB
yundream@@yundream:~/wrk$ 
}}}

2코어
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://192.168.56.100:8000
Running 10s test @@ http://192.168.56.100:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.41ms    3.42ms  63.99ms   94.49%
    Req/Sec     2.56k   529.04    10.60k    77.65%
  291187 requests in 10.00s, 35.55MB read
Requests/sec:  29119.62
Transfer/sec:      3.55MB
}}}

4코어
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://192.168.56.100:8000
Running 10s test @@ http://192.168.56.100:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.85ms   27.85ms 202.11ms   97.99%
    Req/Sec     2.93k   659.80     9.00k    81.55%
  333273 requests in 10.00s, 40.68MB read
Requests/sec:  33343.09
Transfer/sec:      4.07MB
}}}

8코어
{{{#!plain
$ wrk -t 12 -c 100 -d10s http://192.168.56.100:8000
Running 10s test @@ http://192.168.56.100:8000
  12 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    24.08ms   53.59ms 222.75ms   91.42%
    Req/Sec     1.09k   590.80     3.85k    65.15%
  126122 requests in 10.00s, 15.40MB read
Requests/sec:  12607.04
Transfer/sec:      1.54MB
}}}

=== AWS에서 테스트 ===
=== 결과 정리 ===
{{{#!html
	<script type="text/javascript"
		src="https://www.google.com/jsapi?autoload={
		'modules':[{
			'name':'visualization',
			'version':'1',
			'packages':['corechart']
		}]
  }"></script>

<script type="text/javascript">
	google.setOnLoadCallback(drawChart);

function drawChart() {
	var data = google.visualization.arrayToDataTable([
			['core', 'Local', 'Remote'],
			['1',  80835,      13602],
			['2',  155817,     29119],
			['4',  195280,     33343],
			['8',  193031,     12607]
			]);

	var options = {
title: 'Go HTTP 성능 측정',
	   curveType: 'function',
	   legend: { position: 'bottom' }
	};

	var chart = new google.visualization.LineChart(document.getElementById('curve_chart'));

	chart.draw(data, options);
a114 2
</script>
<div id="curve_chart" style="width: 600px; height: 400px"></div>
d116 1
@


1.11
log
@119.64.102.68;;yundream;;
@
text
@d40 9
a180 2
AWS 환경이 구축되면 테스트 해봐야 겠다.

@


1.10
log
@119.64.102.68;;yundream;;
@
text
@d6 1
a6 1
다양한 언어로 테스트 해야 겠는데, 우선 GO 언어로 테스트를 진행하고, Python, Ruby, Java 기반 녀석들과 비교를 해보고 싶다. "Hello World"찍는 거다. 뭔가 거창한 결과를 얻기는 힘들테다.
@


1.9
log
@119.64.102.68;;yundream;;
@
text
@d6 1
a6 2
다양한 언어로 테스트 해야 겠는데, 우선 GO 언어로 테스트를 진행하고, Python, Ruby, Java 기반 녀석들과 비교를 해보고 싶다.

@


1.8
log
@119.64.102.68;;yundream;;
@
text
@d44 1
a44 1
코어의 숫자를 바꿔 가면서 테스트했다.
d103 108
a210 1
뭐 당연한 결과인가 ?
@


1.7
log
@119.64.102.68;;yundream;;
@
text
@d2 1
a2 1
[[TaboeOfContents]]
@


1.6
log
@119.64.102.68;;yundream;;
@
text
@d2 1
a2 1

a103 32
{{{#!html
<script type="text/javascript"
		src="https://www.google.com/jsapi?autoload={
		'modules':[{
			'name':'visualization',
				'version':'1',
				'packages':['line']
		}]
  }">
</script>

<script type="text/javascript">
google.setOnLoadCallback(drawChart);
function drawChart() {
	var data = google.visualization.arrayToDataTable([
			['Core', 'Req/Sec'],
			['1',  80835],
			['2',  155817],
			['4',  195280]
			]);

	var options = {
       title: 'HTTP 벤치마크 테스트',
	};

	var chart = new google.visualization.LineChart(document.getElementById('curve_chart'));

	chart.draw(data, options);
}
</script>
<div id="curve_chart" style="width: 900px; height: 500px"></div>
}}}
@


1.5
log
@119.64.102.68;;yundream;;
@
text
@d110 1
a110 1
				'packages':['corechart']
a119 1
			['0',  0],
a126 2
	   curveType: 'function',
	   legend: { position: 'bottom' }
@


1.4
log
@119.64.102.68;;yundream;;
@
text
@d123 1
a123 1
			['3',  195280]
@


1.3
log
@119.64.102.68;;yundream;;
@
text
@d120 1
d127 1
a127 1
title: 'HTTP 벤치마크 테스트',
a128 1
	   hAxis.minValue: 0,
@


1.2
log
@119.64.102.68;;yundream;;
@
text
@d128 1
@


1.1
log
@119.64.102.68;;yundream;;
@
text
@d119 4
a122 5
			['Year', 'Sales', 'Expenses'],
			['2004',  1000,      400],
			['2005',  1170,      460],
			['2006',  660,       1120],
			['2007',  1030,      540]
d126 1
a126 1
title: 'Company Performance',
@
