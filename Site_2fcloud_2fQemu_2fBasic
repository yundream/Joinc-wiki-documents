#title Qemu를 이용한 가상화 기초

[[TableOfContents]]
== Qemu에 관심을 가진 이유 ==
지금 uCloud의 프로젝트를 진행하고 있습니다. uCloud는 Xen을 기반으로 하고 있는데, Xen은 전가상화와 완전가상화 (HVM)를 모두 지원합니다. Xen은 완전 가상화를 위해서 Qemu를 이용합니다. 결국 Xen 전 가상화를 이해하려면 Qemu를 살펴봐야 되겠다는 생각이 들더군요. Qemu를 살펴보게된 이유입니다.

== Qemu에 대하여 ==
Qemu는 PC 환경을 위한 프로세스 에뮬레이터로 프로세스뿐만 아니라 각종 주변기기까지를 에뮬레이터 합니다. 하나의 가상 컴퓨터를 구축해 주는 소프트웨어입니다. vmware, Xen, Virtualbox와 같은 가상화(:12) 솔루션의 하나로 보시면 됩니다.

Qemu는 HVM 방식을 지원합니다. Guest 운영체제가 하드웨어 자원에 대한 접근을 요청할 때, 이 요청을 Qemu로 요청을 보냅니다. 요청을 받은 Qemu는 이명령을 변환해서 하드웨어로 전달을 해서 요청을 처리합니다. 완전한 하드웨어 애뮬레이션 위에서 guest 운영체제가 작동하는 방식이기 때문에, 커널 수정 없이 운영체제를 돌릴 수 있다는 장점이 있습니다. 진정한 하드웨어 가상 머신이라고 볼 수 있는 거죠.

대신 Qemu가 애뮬레이션하는 하드웨어의 지원 범위에 따라서 guest 운영체제의 성능이 제한될 수 있다는 장점이 있습니다. 예컨데 10 Gbits/sec의 대역폭을 가진 네트워크 디바이스가 꽂혀있다고 하더라도, Qemu가 100 Mbits/sec의 대역폭을 가지는 rtl8139 디바이스를 지원한다면 guest 운영체제는 100 Mbits의 대역폭만 사용할 수 있을 따름입니다.   

XenServer의 경우 rtl8139만을 사용하도록 하드코딩된 Qemu를 사용합니다. 때문에 전가상화로 올라간 운영체제는 100Mbits/sec의 대역폭만을 사용할 수 있습니다. 왜 하드코딩을 했는지 모르겠습니다. 최근 출시된 Xenserver 6.0은 어떨지 모르겠습니다. 

=== Qemu와 KVM ===
KVM은 리눅스 커널기반의 HVM 방식을 지원하는 하이퍼바이저로 유저 영역에서 가상화 기능을 사용할 수 있습니다. HVM을 위해서는 애물레이션이 필요한데, Qemu를 사용하고 있습니다. KVM의 가장 중요한 구성요소라고 할 수 있습니다. 커널 2.6.20 부터 리눅스 커널에 포함됐습니다. KVM을 한다는 것은 Qemu를 한다는 것과 동일하다고 보시면 됩니다. 실제 /usr/bin/kvm은 qemu의 심볼릭 링크입니다.  
{{{#!plain
$ ls -al /usr/bin/kvm
lrwxrwxrwx 1 root root 18  4월 13 07:02 /usr/bin/kvm -> qemu-system-x86_64   
}}}

== Qemu 설치 ==
qemu 설치 환경입니다.
  * ubuntu 11.10 i386
    개발 용도로 사용하는 리눅스 노트북에 설치한 운영체제입니다.
  * kernel : 3.0.0-13-generic

우분투 패키지 관리자로 qeme를 설치합니다.
{{{#!plain
# apt-get install qemu
}}}
qemu를 설치하면 아래와 같은 부가 패키지들이 함께 설치됩니다.
  * bridge-utils
  * libaio1
  * qemu-common
  * qemu-kvm
  * seabios 
  * vgabios

== guest 운영체제 올리기 ==
먼저 guest 운영체제를 올릴 디스크 이미지를 만듦니다. 디스크 이미지의 형식은 vdi로 선택했습니다. vdi는 virtualbox에서 사용하는 가상 디스크 형식입니다. 4기가 바이트 크기로 만들었습니다. 
{{{#!plain
# qemu-img create -f vdi ubuntu11-server.vdi 4G
}}}

앞서 만든 디스크 이미지에 우분투 리눅스를 설치합니다. cdrom 형식으로 iso 파일을 읽도록 했습니다. 
{{{#!plain
# qemu-system-i386 -cdrom ubuntu-11.04-server-i386.iso -k en-us ubuntu11-server.vdi
qemu-system-i386: pci_add_option_rom: failed to find romfile "pxe-rtl8139.bin"
}}}
설치는 잘 되는데, "pxe-rtl839.bin" 롬파일을 찾지 못했다는 메시지가 거슬립니다. guest 운영체제에서 이더넷 카드를 사용하려면 해당 롬파일을 올려야 합니다. kvm-pxe 패키지를 설치하면 됩니다. rtl8139를 비롯해서 몇 개의 이더넷 카드 롬이 함께 설치되는 군요.
{{{#!plain
# sudo apt-get install kvm-pxe
# dpkg -L kvm-pxe
/usr/share/qemu/pxe-rtl8139.bin
/usr/share/qemu/pxe-pcnet.bin
/usr/share/qemu/pxe-virtio.bin
/usr/share/qemu/pxe-ne2k_pci.bin
/usr/share/qemu/pxe-e1000.bin
}}}

설치를 끝내고 guest 운영체제를 실행했습니다.
{{{#!plain
$ qemu-system-i386 -k en-us ubuntu11-server.vhd 
}}}
{{{#!html
<table style="width:auto;"><tr><td><a href="https://picasaweb.google.com/lh/photo/Z2A_PTYbBd7CC2oqvdazytMTjNZETYmyPJy0liipFm0?feat=embedwebsite"><img src="https://lh6.googleusercontent.com/-BuRetNCRCU8/TtpLv5O0EQI/AAAAAAAAB6Y/_RQCVDW1-Ng/s640/2.png" height="486" width="640" /></a></td></tr><tr><td style="font-family:arial,sans-serif; font-size:11px; text-align:right">보낸 사람 <a href="https://picasaweb.google.com/yundream/Linux?authuser=0&feat=embedwebsite">Linux</a></td></tr></table>
}}}

=== 지원하는 vhd 형식 ===
qemu에서 지원하는 vhd 형식입니다.
  * raw 
  * cloop
  * cow
    copy-on-write 형식으로 윈도우 Qemu에서는 사용할 수 없습니다. 역사적인 이유로 지원한다는 걸로 봐서 그다지 사용하지 않는 형식인 것 같습니다.  
  * qcow2
  * vmdk 
    VMware의 vhd 형식
  * vdi 
    virtualbox의 vhd 형식 

=== 이미지 생성과 관리 ===
게스트 운영체제를 만들기 위해서는 게스트 운영체제를 올리기 위한 디스크가 있어야 합니다. 이미지는 qemu-img로 만들 수 있습니다. qcow2 형식의 3G이미지를 만들었습니다. 
{{{#!plain
# qemu-img create -f qcow2 myLinux.img 3G
}}}

이제 만든 디스크에 운영체제를 설치하면된다. 운영체제를 설치하는 가장 손쉬운 방법은 iso 파일을 cdrom에 구워서 부팅하는 것이다. ubuntu-server-11.10.iso를 설치하는 방법으로, 설치시 사용할 메모리로 256M을 할당했다. 
{{{#!plain
# qemu -m 256 -hda myLinux.img -cdrom ubuntu-server-11.10.iso -boot d
}}}

iso 파일이 아닌, 컴퓨터 시스템의 CD나 DVD를 이용해서 설치할 수도 있습니다. 
{{{#!plain
# qemu -m 256 -hda myLinux.img -cdrom /dev/cdrom -boot d
}}}

=== 여러 이미지 사용하기 ===
Qemu는 게스트 운영체제에 최대 4개의 이미지 파일을 줄 수 있습니다. 이들 이미지 파일은 다음의 용도로 사용할 수 있습니다.  
  * 추가적인 물리 디스크 
  * 만약 호스트 운영체제가 여러 개의 디스크를 가지고 있다면, 이미지 파일을 물리적으로 분산할 수 있을 겁니다. 그러면 게스트 운영체제에도 물리적으로 나뉜 디스크를 제공할 수 있습니다.  aa
{{{#!plain
# qemu -m 256 -hda myLinux.img -hdb temp.img -hdc db.img
}}}

=== Copy on Write ===
Copy on Write는 컴퓨터 공학의 여러 분야에서 사용 합니다. fork에서 자식 프로세스를 만들기 위해서 사용하며, STL의 string에서 문자열 복사에도 사용하죠. 데이터 변경이 일어나면, 변경이 일어난 부분을 다른 부분에 복사한 다음 쓰는 방식입니다. 소프트웨어 개발에서는 메모리를 대상으로 하겠고, 파일 시스템이라면 디스크를 대상으로 합니다. 

Qemu의 "cow"와 "qcow2"는 copy on write를 지원하는 디스크 포멧으로, 원본 디스크 이미지를 copy on write 방식으로 해서 새로운 디스크 이미지를 생성할 수 있습니다. 주로 소프트웨어 개발과 테스팅을 위한 개발 환경을 만들기 위해서 사용합니다. 원본 디스크 이미지에 개발 환경을 세팅해 놓은 다음 copy on write 이미지를 생성하면, 원본 개발환경을 그대로 유지한체 다양한 방식으로 테스트 할 수 있기 때문입니다. 

ubunt11-server 이미지로 웹서버용 테스트 이미지인 ubunt11-webserver.img를 만들었습니다. -b 옵션뒤에 원본 이미지를 명시하면 됩니다.
{{{#!plain
$ qemu-img create -f qcow2 -b ubuntu11-server.vdi ubuntu11-webserver.img
}}}
테스트를 해본결과, 디스크 용량을 크게 줄일 수 있지만 상당히 느리다는 느낌을 받았습니다. 디스크 공간을 낭비하더라도 원본을 복사해서 사용하는게 낫다는 생각입니다. 

=== 디스크 이미지 마운트 하기 ===
때때로 디스크 이미지를 호스트에서 마운트해서 사용해야할 때가 있습니다. 예를 들어 게스트 운영체제가 네트워크에 연결되지 않았는데, 파일을 옮겼으면 할 때가 있습니다. 혹은 패스워드를 잃어버려서 초기화하는 등의 작업도 필요합니다. 이럴 때 디스크 이미지를 loopback로 마운트 해서 파일 작업하듯 작업하면 됩니다. .
{{{#!plain
# mount -o loop,offset=32256 Centos.img /mnt/mpoint
}}}
하지만 디스크 이미지가 LVM등을 사용하고 있다면 mount 명령으로 마운트할 수 없습니다. 이 경우 qemu-nbd 명령을 이용해야 합니다. 
{{{#!plain
# modprobe nbd max_part=16
# qemu-nbd -c /dev/nbd0 Centos.img
# partprobe /dev/nbd0
}}}

이제 fdisk로 Centos.img 디스크의 파티션 정보를 확인할 수 있습니다. 
{{{#!plain
# fdisk /dev/nbd0

Command (m for help): p

Disk /dev/nbd0: 2147 MB, 2147483648 bytes
255 heads, 63 sectors/track, 261 cylinders, total 4194304 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x0009a4f6

     Device Boot      Start         End      Blocks   Id  System
/dev/nbd0p1   *        2048     1026047      512000   83  Linux
/dev/nbd0p2         1026048     4194303     1584128   8e  Linux LVM
}}}
nbd0p2는 LVM 파티션이므로 mount 명령으로 마운트 할수 없습니다. LVM 명령을 이용해서 마운트 해야 합니다.
{{{#!plain
# vgscan
  Reading all physical volumes.  This may take a while...
  Found volume group "CentOSVolGroup" using metadata type lvm2
}}}

볼륨 그룹이름으로 mount 합니다. 
{{{#!plain
# mount /dev/CentOSVolGroup/lv_root /mnt/mpoint2/
# cp mydata.txt /mnt/mpoint2/home/yundream
}}}

=== 이미지 정보 얻기 ===
{{{#!plain
# qemu-img info CentOS.img 
image: CentOS.img
file format: raw
virtual size: 2.0G (2147483648 bytes)
disk size: 1.1G
}}}

== qemu와 HVM ==
Xen과 KVM은 Qemu를 이용해서 전가상화를 구현하고 있습니다. virtualbox의 경우 운영체제 레벨에서 전가상화를 지원하는데, 역시 QEMU를 이용하고 있습니다. Xen, KVM, VirtualBox의 구조에 대해서는 따로 위키페이지를 만들어서 공부해볼 생각입니다. 

== 리눅스 KVM과 Qemu ==
리눅스는 KVM이라는 커널레벨의 가상화 환경을 지원합니다. 원래는 커널 패치형태로 지원이 됐는데, 2.6.20 버전부터 정식으로 커널에 포함됐으며, 공식 리눅스 패키지의 일부로 제공되고 있습니다. KVM은 Qemu를 기반으로 구현돼 있습니다.  

{{{#!html
<img src="https://docs.google.com/drawings/pub?id=1GVUVxXbqLSHjy6l_aSKpTokbIFG3Zh08EdsiYKeZ3mI&amp;w=370&amp;h=336">
}}}

== 다음에 하고 싶은 것들 ==
 1. 리눅스 KVM
 1. Qemu 네트워크

== 참고 문헌 ==
 1. [wiki:Site/cloud/QemuNetwork Qemu 네트워크]
 1. http://wiki.qemu.org 

== 히스토리 ==
 * 2011년 12월 3일

[[tag(가상화,Xen,KVM,Qemu,Virtualbox,20111203)]]
[[Category(50)]]
