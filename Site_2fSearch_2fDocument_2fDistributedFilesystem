#title Distributed Filesystem

== 소개 ==
검색엔진은 테라급의 대량의 데이터를 다루어야 한다. 때문에 검색엔진을 구축하기 위해서는 대량의 데이터를 저장가능한 툴이 제시되어야 한다. 가장 확실하고도 간단한 방법은 수십 테라급의 저장공간을 지원하는 하나의 저장시스템을 확보하는게 되겠지만 이를 위해서는 엄청난 비용이 지불되어야 한다. 이러한 문제를 해결하기 위해서 제안된게 '''Distributed Filesystem'''이다. 기본 아이디어는 여러대의 조그마한 저장공간을 가진 시스템을 네트워크로 묶어서 하나의 파일시스템 처럼 보이도록 하는데 있다. 

=== NFS와 Distributed Filesystem ===
Distributed Filesystem이 Network를 통해서 파일 시스템을 구축한다는 점 때문에, NFS등의 네트워크 파일시스템과 혼동될 여지가 있는데, 네트워크 파일시스템과 분산 파일시스템은 성격이 전혀 다르다.   

네트워크 파일시스템은 파일시스템을 분산하기 위한 목적이 아닌 '''공유'''하기 위한 목적으로 사용된다. 
{{{#!plain
  단일 Node
  저장공간
 +----------+            +------------+
 | NFS      |       +--->| NFS Client |
 | SERVER   |       |    +------------+
 | 10 Tera  |       |    +------------+
 |          |<------+--->| NFS Client |
 |          |       |    +------------+
 |          |       |    +------------+
 |          |       +--->| NFS Client |
 |          |            +------------+
 +----------+           
}}}
NFS는 대량의 저장공간을 가지는 하나의 서버에서 데이터를 유지하고, 이를 Client에서 네트워크를 이용해서 접근을 하는 시스템이다. FTP(:12)와 동일하다고 볼 수 있다. FTP와 다른점이라면, Client운영체제의 커널레벨에서 네트워크로 연결된 자원을 마치 로컬파일시스템처럼 인식하도록 도와준다는 점 정도이다.     

{{{#!plain
 +-----------+
 | DF Node 1 |-----+           
 | 1 Tera    |     |           +----------+
 +-----------+     |-----------| Client   |
 +-----------+     |           +----------+
 | DF Node 2 |-----+ 
 | 1 Tera    |     |           +----------+
 +-----------+     |-----------| Client   |
 +-----------+     |           +----------+
 | DF Node 3 |-----+
 | 1 Tera    |     | 
 +-----------+     |
 +-----------+     |
 | DF Node 4 |-----+
 | 1 Tera    |
 +-----------+
 ....
 ....
}}}
반면 분산파일 시스템은 여러개의 작은 작은 저장공간을 가진 시스템을 네트워크를 이용해서 통합하고, Client 입장에서는 지역파일 시스템인 것처럼 보이도록 하는 시스템이다.  

== Global File System ==
== Google File System ==
== Hadoop ==
=== 소개 ===
Hadoop은 Lucene의 서브프로젝트로 개발되고 있는 분산 파일시스템 으로, Nutch(:12)에서도 사용되어지고 있다. Hadoop는 Hadoop Distributed Filesystem(HDFS)와 이의 구현을 위한 MapReduce를 포함하고 있다.    
=== OverView ===
Hadoop는 대용량 분산 시스템의 구성을 지원하기 위한 라이브러리와 프로그램의 모음으로 엔진을 만들기 위한 많은 구성들을 가지고 있다.
 * conf : 시스템 설정을 위한 key-value를 제어할 수 있는 클래스들의 집합  
 * DFS : Hadoop Distributed Filesystem 
 * io : 입출력 관련 클래스. UTF8 문자열 제어클래스와, 외부 소트, 대량의 key-value 셋을 유지하기 위한 poor-man's B-Tree 코드를 가지고 있다. 
 * ipc : Remote Procedure call System의 지원을 위해서 사용한다.  
 * HadoopMapReduce : DFS상에서 이루어지는 분산관련 작업의 수행을 지원한다. MapReduce(:12) 프로그래밍 모델을 따른다.  
